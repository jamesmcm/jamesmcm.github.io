{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.  Error handling: Call the given function repeatedly to produce a list of 100 integers between 1 and 10 (inclusive). Ignore any exceptions and any values outside of this range (these do not count towards the 100 integers). Sum this list of 100 integers.\n",
    "\n",
    "**Justification**:\n",
    "\n",
    "We often have to work with APIs that may throw errors in some cases, here we simulate a malfunctioning API.\n",
    "\n",
    "\n",
    "**Details:**\n",
    "\n",
    "Call the given function repeatedly to produce a list of 100 integers between 1 and 10 (inclusive).\n",
    "\n",
    "Ignore any exceptions and any values outside of this range (these do not count towards the 100 integers). \n",
    "\n",
    "Sum this list of 100 integers.\n",
    "\n",
    "Your output should be an integer, that is the sum of the 100 integer list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of 100 integers: 559\n",
      "Number of integers collected: 100\n",
      "First 10 values: [1, 5, 2, 7, 5, 2, 1, 7, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def badRandomNumber() -> int:\n",
    "    x = random.randint(1, 15)\n",
    "    if x > 12:\n",
    "        raise ValueError\n",
    "    return x\n",
    "\n",
    "output = []\n",
    "random.seed(123)  # Do not edit the seed\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# Need to call badRandomNumber repeatedly until we get 100 valid integers (1-10 inclusive)\n",
    "# Ignore exceptions and values outside 1-10 range\n",
    "\n",
    "while len(output) < 100:\n",
    "    try:\n",
    "        value = badRandomNumber()\n",
    "        # Only add values between 1 and 10 inclusive\n",
    "        if 1 <= value <= 10:\n",
    "            output.append(value)\n",
    "    except ValueError:\n",
    "        # Ignore exceptions and continue\n",
    "        continue\n",
    "\n",
    "# Sum the list of 100 integers\n",
    "result = sum(output)\n",
    "print(f\"Sum of 100 integers: {result}\")\n",
    "print(f\"Number of integers collected: {len(output)}\")\n",
    "print(f\"First 10 values: {output[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Regex: Extract the city code and start date from the campaign names\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Sometimes we have to parse legacy marketing data, here we have some extreme fabricated cases to demonstrate the difficulties in such parsing.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "The city code is an upper case 3 character code, valid entries are given in _cityset_.\n",
    "\n",
    "The start date will always be in the form YYYYMMDD.\n",
    "\n",
    "Your output should be of the form: campaign_name, city_code, start_date\n",
    "\n",
    "You may assume all campaigns occur between 2017 and 2030."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB_CDB_20180911, CDB, 20180911\n",
      "ADWORDS_AND_BUE_20181101, BUE, 20181101\n",
      "FB_CPC_MAD(20180301), MAD, 20180301\n",
      "20180521_Retargeting_BRANCH_iOS_MAD, MAD, 20180521\n",
      "ACT_110022412_Instagram_TGT_BCN_20190101, BCN, 20190101\n",
      "NEW_MAD_ACT_88993412_20180503, MAD, 20180503\n",
      "FB_CDB20190301, CDB, 20190301\n",
      "INSTA_ACT_20188823_BCN_20191121, BCN, 20191121\n",
      "NOMAD_CPC_BCN_20191121(BCN), BCN, 20191121\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "cityset = set(['BUE', 'MAD', 'BCN', 'CDB'])\n",
    "\n",
    "campaigns = [\n",
    "    \"FB_CDB_20180911\",\n",
    "    \"ADWORDS_AND_BUE_20181101\",\n",
    "    \"FB_CPC_MAD(20180301)\",\n",
    "    \"20180521_Retargeting_BRANCH_iOS_MAD\",\n",
    "    \"ACT_110022412_Instagram_TGT_BCN_20190101\",\n",
    "    \"NEW_MAD_ACT_88993412_20180503\",\n",
    "    \"FB_CDB20190301\",\n",
    "    \"INSTA_ACT_20188823_BCN_20191121\",\n",
    "    \"NOMAD_CPC_BCN_20191121(BCN)\",\n",
    "]\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# Extract city code (3-char uppercase from cityset) and date (YYYYMMDD format, 2017-2030)\n",
    "# Output format: campaign_name, city_code, start_date\n",
    "\n",
    "results = []\n",
    "\n",
    "for campaign in campaigns:\n",
    "    # Find city code - look for any of the valid city codes\n",
    "    city_code = None\n",
    "    for city in cityset:\n",
    "        if city in campaign:\n",
    "            city_code = city\n",
    "            break\n",
    "    \n",
    "    # Find start date - YYYYMMDD format between 2017-2030\n",
    "    # More precise pattern: year 2017-2030, month 01-12, day 01-31\n",
    "    date_pattern = r'(201[7-9]|202[0-9])((0[1-9])|(1[0-2]))((0[1-9])|([12][0-9])|(3[01]))'\n",
    "    date_matches = re.findall(date_pattern, campaign)\n",
    "    \n",
    "    # Reconstruct the full date from the groups\n",
    "    start_date = None\n",
    "    if date_matches:\n",
    "        # Take the first valid match and reconstruct\n",
    "        match = date_matches[0]\n",
    "        year = match[0]  # 2017-2030\n",
    "        month = match[1]  # 01-12\n",
    "        day = match[4]    # 01-31\n",
    "        start_date = year + month + day\n",
    "    \n",
    "    if city_code and start_date:\n",
    "        results.append((campaign, city_code, start_date))\n",
    "\n",
    "# Print results\n",
    "for campaign_name, city_code, start_date in results:\n",
    "    print(f\"{campaign_name}, {city_code}, {start_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Timestamp handling: Find the seconds between two integer timestamps\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Some legacy data may be stored in strange representations, in this example you must handle a timestamp stored in an unusual format.\n",
    "\n",
    "\n",
    "**Details:**\n",
    "\n",
    "You are provided two timestamps as integers in the form HHMMSS (assume they are on the same day).\n",
    "\n",
    "Write a function to calculate the number of seconds between the timestamps.\n",
    "\n",
    "Note that leading 0s will not be present since the timestamps are stored as an integer i.e. 05:05:05 becomes 50505.\n",
    "\n",
    "If the end time is earlier than the start time you should raise a ValueError.\n",
    "\n",
    "Can you do it without conversion to strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference: 7200 seconds\n",
      "Test 1: 60 seconds\n",
      "Test 2: 3600 seconds\n"
     ]
    }
   ],
   "source": [
    "def timediff(start: int, end: int) -> int:\n",
    "    ### YOUR CODE HERE\n",
    "    # Convert HHMMSS integer format to seconds without string conversion\n",
    "    # Extract hours, minutes, seconds using integer arithmetic\n",
    "    \n",
    "    # For start time\n",
    "    start_seconds = start % 100  # Last 2 digits\n",
    "    start_minutes = (start // 100) % 100  # Middle 2 digits  \n",
    "    start_hours = start // 10000  # First 1-2 digits\n",
    "    \n",
    "    # For end time\n",
    "    end_seconds = end % 100\n",
    "    end_minutes = (end // 100) % 100\n",
    "    end_hours = end // 10000\n",
    "    \n",
    "    # Convert to total seconds from midnight\n",
    "    start_total_seconds = start_hours * 3600 + start_minutes * 60 + start_seconds\n",
    "    end_total_seconds = end_hours * 3600 + end_minutes * 60 + end_seconds\n",
    "    \n",
    "    # Check if end time is earlier than start time\n",
    "    if end_total_seconds < start_total_seconds:\n",
    "        raise ValueError(\"End time is earlier than start time\")\n",
    "    \n",
    "    diff = end_total_seconds - start_total_seconds\n",
    "    return diff\n",
    "\n",
    "# Test the function\n",
    "result = timediff(33000, 53000)  # Should return 7200\n",
    "print(f\"Time difference: {result} seconds\")\n",
    "\n",
    "# Additional test cases\n",
    "print(f\"Test 1: {timediff(50505, 50605)} seconds\")  # 1 minute difference\n",
    "print(f\"Test 2: {timediff(120000, 130000)} seconds\")  # 1 hour difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "These questions are designed to test your SQL skills, here you should use Postgres SQL (note that we use Amazon Redshift in production).\n",
    "\n",
    "Here we provide the connection details to the Postgres server and print the schema.\n",
    "\n",
    "Run the cell below and continue to the SQL problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tables:\n",
      "scheduled_slots\n",
      "\tslot_time :: timestamp without time zone\n",
      "\tcourier_id :: integer\n",
      "orders\n",
      "\tcreation_time :: timestamp without time zone\n",
      "\torder_id :: bigint\n",
      "\tuser_id :: bigint\n",
      "enabling_log\n",
      "\tcreation_time :: timestamp without time zone\n",
      "\tcourier_id :: bigint\n",
      "\tenabled :: boolean\n",
      "opening_times\n",
      "\tstore_id :: integer\n",
      "\topening_times :: character varying\n",
      "unplanned_closure_log\n",
      "\tstore_id :: integer\n",
      "\tstart_time_utc :: timestamp without time zone\n",
      "\tend_time_utc :: timestamp without time zone\n",
      "city_work_days\n",
      "\twork_days :: integer\n",
      "\tcity_code :: character varying\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\"dbname=postgres host=db user=postgres password=postgres\")\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"\"\"\\\n",
    "SELECT table_name\n",
    "FROM   information_schema.tables\n",
    "WHERE  table_schema = 'public'\n",
    "       AND table_type = 'BASE TABLE';\"\"\")\n",
    "\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"# Tables:\")\n",
    "for table in tables:\n",
    "    print(f\"{table[0]}\")\n",
    "    cursor.execute(\"SELECT column_name, data_type FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = %s;\", table)\n",
    "    columns = cursor.fetchall()\n",
    "    for column, dtype in columns:\n",
    "        print(f\"\\t{column} :: {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Get the order_id of the most recent order for each user in the orders table - give the output with the user_id in ascending order\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Often we need to get the most recent order ID for a customer, or other fields pertaining to their most recent order.\n",
    "\n",
    "\n",
    "**Details:**\n",
    "\n",
    "Note you cannot rely upon the order_id being incremental with time.\n",
    "\n",
    "Note above, that the *orders* table is of the form: creation_time, order_id, user_id.\n",
    "\n",
    "Do this in SQL only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id, last_order_id\n",
      "289796, 4509163\n",
      "904841, 5134211\n",
      "925762, 4933672\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Get the order_id of the most recent order for each user\n",
    "-- Note: cannot rely on order_id being incremental with time\n",
    "-- Need to use creation_time to find most recent order\n",
    "-- Output should have user_id in ascending order\n",
    "\n",
    "SELECT \n",
    "    user_id,\n",
    "    order_id\n",
    "FROM (\n",
    "    SELECT \n",
    "        user_id,\n",
    "        order_id,\n",
    "        creation_time,\n",
    "        ROW_NUMBER() OVER (PARTITION BY user_id ORDER BY creation_time DESC) as rn\n",
    "    FROM orders\n",
    ") ranked_orders\n",
    "WHERE rn = 1\n",
    "ORDER BY user_id ASC;\n",
    "\"\"\")\n",
    "\n",
    "print('user_id, last_order_id')\n",
    "print('\\n'.join(', '.join(map(str, x)) for x in cursor.fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Calculate the average length of distinct sessions across all couriers from scheduled_slots\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Couriers work by booking hourly slots in which they are available to fulfill orders. These slots booked by couriers are in the *scheduled_slots* table. \n",
    "\n",
    "We would like to know the average length of time that couriers work in a continuous session (back to back slots).\n",
    "\n",
    "**Details:**\n",
    "\n",
    "A distinct session consists of one or more consecutive slots, that is, if the courier works 08-09am, 09-10am, and 10-11am together, that counts as one distinct session with a length of 3 hours.\n",
    "\n",
    "Consecutive slots are slots done in one go, one after another, by the same courier - i.e. one hour on its own counts as one such slot, i.e. one distinct session of length 1 hour.\n",
    "\n",
    "Two slots are consecutive (i.e. part of the same session) if they have exactly an hour's difference between their start_time's (as slots are per hour) and they have the same courier_id.\n",
    "\n",
    "Note that we want the average length of the distinct sessions across all couriers, not the average of the average session length per courier.\n",
    "\n",
    "Your output should be one number i.e. 7.243 for the average over all couriers.\n",
    "\n",
    "The slots carried out by couriers are in the *scheduled_slots* table, with the colums: slot_time, courier_id\n",
    "\n",
    "(Ignore the enabling_log table for this question)\n",
    "\n",
    "Try to do this in SQL only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average session length: 3.1428571428571429\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Calculate average length of distinct sessions across all couriers\n",
    "-- A session is consecutive slots (exactly 1 hour apart) by same courier\n",
    "-- Need to identify session boundaries and calculate session lengths\n",
    "\n",
    "WITH slot_groups AS (\n",
    "    -- Identify consecutive slots by looking at gaps\n",
    "    SELECT \n",
    "        courier_id,\n",
    "        slot_time,\n",
    "        slot_time - INTERVAL '1 hour' * ROW_NUMBER() OVER (PARTITION BY courier_id ORDER BY slot_time) AS group_identifier\n",
    "    FROM scheduled_slots\n",
    "),\n",
    "session_lengths AS (\n",
    "    -- Count slots in each session group\n",
    "    SELECT \n",
    "        courier_id,\n",
    "        group_identifier,\n",
    "        COUNT(*) as session_length\n",
    "    FROM slot_groups\n",
    "    GROUP BY courier_id, group_identifier\n",
    ")\n",
    "SELECT AVG(session_length) as average_session_length\n",
    "FROM session_lengths;\n",
    "\"\"\")\n",
    "\n",
    "result = cursor.fetchall()\n",
    "print(f\"Average session length: {result[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Calculate the proportion of time the courier was enabled during each scheduled slot\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Couriers may be active or inactive during slots they have scheduled, corresponding to whther they wish to receive orders in that moment. \n",
    "\n",
    "We would like to know the proportion of the slot (i.e. out of 1 hour) that each courier was enabled during each slot they were booked for.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "In the table *scheduled_slots* you have each slot (of duration 1 hour), that couriers were booked for.\n",
    "\n",
    "In the table *enabling_log*, you have the timestamps when the couriers were either enabled or disabled.\n",
    "\n",
    "If a courier has no entry in enabling_log, you should assume they were never enabled (i.e. disabled for all time).\n",
    "\n",
    "If a courier's first entry in enabling_log is True, you should assume they were disabled prior to that entry.\n",
    "\n",
    "If a courier's first entry in enabling_log is False, you should assume they were enabled prior to that entry.\n",
    "\n",
    "Note that the couriers can toggle the enabled flag at any time, including outside of their booked slots.\n",
    "\n",
    "For each courier slot in *scheduled_slots*, calculate the proportion of the 60-minute slot for which the courier was enabled.\n",
    "\n",
    "Your output should be of the form: courier_id, slot_start_time, proportion_enabled\n",
    "\n",
    "Where proportion_enabled will be a numeric value between 0 and 1 inclusive.\n",
    "\n",
    "Try to do this in SQL only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2018-03-15 11:00:00, 0.000000\n",
      "1, 2018-03-15 12:00:00, 0.893056\n",
      "1, 2018-03-15 13:00:00, 1.000000\n",
      "1, 2018-03-15 14:00:00, 1.000000\n",
      "1, 2018-03-15 15:00:00, 0.284444\n",
      "2, 2018-03-15 01:00:00, 0.546944\n",
      "2, 2018-03-15 02:00:00, 0.000000\n",
      "2, 2018-03-15 03:00:00, 0.619722\n",
      "2, 2018-03-15 04:00:00, 1.000000\n",
      "2, 2018-03-15 08:00:00, 1.000000\n",
      "2, 2018-03-15 09:00:00, 1.000000\n",
      "2, 2018-03-15 10:00:00, 1.000000\n",
      "2, 2018-03-15 11:00:00, 1.000000\n",
      "2, 2018-03-15 12:00:00, 1.000000\n",
      "3, 2018-03-15 10:00:00, 0.000000\n",
      "3, 2018-03-15 11:00:00, 0.532778\n",
      "3, 2018-03-15 12:00:00, 0.000000\n",
      "3, 2018-03-15 13:00:00, 0.000000\n",
      "3, 2018-03-15 18:00:00, 0.000000\n",
      "4, 2018-03-15 13:00:00, 1.000000\n",
      "4, 2018-03-15 14:00:00, 1.000000\n",
      "5, 2018-03-15 13:00:00, 0.000000\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Simplified approach: manual calculation of enabled time per slot\n",
    "WITH courier_states AS (\n",
    "    -- Add row numbers to identify first entry per courier\n",
    "    SELECT \n",
    "        courier_id,\n",
    "        creation_time,\n",
    "        enabled,\n",
    "        ROW_NUMBER() OVER (PARTITION BY courier_id ORDER BY creation_time) as rn\n",
    "    FROM enabling_log\n",
    "),\n",
    "initial_states AS (\n",
    "    -- Determine initial state before first entry\n",
    "    SELECT \n",
    "        courier_id,\n",
    "        CASE \n",
    "            WHEN enabled = TRUE THEN FALSE  -- If first entry is True, assume disabled before\n",
    "            ELSE TRUE  -- If first entry is False, assume enabled before  \n",
    "        END as initial_enabled\n",
    "    FROM courier_states \n",
    "    WHERE rn = 1\n",
    "),\n",
    "all_states AS (\n",
    "    -- Combine initial states with actual log entries\n",
    "    SELECT courier_id, '1900-01-01'::timestamp as change_time, initial_enabled as enabled\n",
    "    FROM initial_states\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT courier_id, creation_time as change_time, enabled\n",
    "    FROM enabling_log\n",
    "),\n",
    "state_periods AS (\n",
    "    -- Create time periods for each state\n",
    "    SELECT \n",
    "        courier_id,\n",
    "        change_time as period_start,\n",
    "        LEAD(change_time, 1, '2099-12-31'::timestamp) OVER (PARTITION BY courier_id ORDER BY change_time) as period_end,\n",
    "        enabled\n",
    "    FROM all_states\n",
    ")\n",
    "SELECT \n",
    "    s.courier_id,\n",
    "    s.slot_time as slot_start,\n",
    "    COALESCE(\n",
    "        SUM(\n",
    "            CASE \n",
    "                WHEN sp.enabled = TRUE THEN\n",
    "                    EXTRACT(epoch FROM (\n",
    "                        LEAST(sp.period_end, s.slot_time + INTERVAL '1 hour') - \n",
    "                        GREATEST(sp.period_start, s.slot_time)\n",
    "                    )) / 3600.0\n",
    "                ELSE 0\n",
    "            END\n",
    "        ) FILTER (WHERE sp.period_start < s.slot_time + INTERVAL '1 hour' AND sp.period_end > s.slot_time),\n",
    "        0\n",
    "    ) as proportion_enabled\n",
    "FROM scheduled_slots s\n",
    "LEFT JOIN state_periods sp ON s.courier_id = sp.courier_id\n",
    "WHERE s.courier_id IN (SELECT DISTINCT courier_id FROM enabling_log)\n",
    "   OR s.courier_id NOT IN (SELECT DISTINCT courier_id FROM enabling_log)\n",
    "GROUP BY s.courier_id, s.slot_time\n",
    "ORDER BY s.courier_id, s.slot_time;\n",
    "\"\"\")\n",
    "\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    courier_id, slot_start, proportion = row\n",
    "    print(f\"{courier_id}, {slot_start}, {proportion:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Calculate the proportion of the day that each store was open on 2018-03-12 (local time)\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "We often need to report on our own availability of services for different stores, and this depends upon knowing for which hours the store was supposed to be open. This is complicated by the fact that the stores can undergo unforeseen closures.\n",
    "\n",
    "In this example we would like to calculate the proportion of the day (of 24 hours) that each store was open on 2018-03-12 (in their local time).\n",
    "\n",
    "(The prevalence of unplanned store closures is exaggerated in this test data)\n",
    "\n",
    "**Details:**\n",
    "\n",
    "In the table *opening_times* you have the scheduled opening times for each store, given in a JSON format and stored as a string. The JSON is formatted with the local timezone for the store, and then an entry for each day of the week with the corresponding list of opening and closing times.\n",
    "\n",
    "The day of the week runs from Monday to Sunday, i.e. Monday: 1, Tuesday: 2 ... Sunday: 7 \n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "  \"timezone\": \"Europe/Madrid\",\n",
    "  \"7\": [\n",
    "    {\n",
    "      \"opening\": \"13:00\",\n",
    "      \"closing\": \"16:00\"\n",
    "    },\n",
    "    {\n",
    "      \"opening\": \"20:00\",\n",
    "      \"closing\": \"23:30\"\n",
    "    }\n",
    "  ],\n",
    "  \"1\": ...\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "The opening and closing times are given in __local__ time, and an opening and closing time of the same hour (i.e. 00:00), means that the store is open 24 hours that day.\n",
    "\n",
    "However, stores can also be closed due to unforeseen circumstances. These closures are logged in the table *unplanned_closure_log* with the start and end times of the closure in __UTC__.\n",
    "\n",
    "For each store in *opening_times*, calculate the proportion of the day (out of 24 hours) that the stores were open for on 2018-03-12 (using the local time, i.e. their local 2018-03-12).\n",
    "\n",
    "Your output should be of the form: store_id, proportion_open\n",
    "\n",
    "Where proportion_open is a numeric value between 0 and 1.\n",
    "\n",
    "It is highly recommended to use Python in addition to SQL in this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 0.125012\n",
      "2, 0.000000\n",
      "3, 0.000000\n",
      "4, 0.437500\n",
      "5, 0.000000\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Get store opening times and closure data for 2018-03-12\n",
    "SELECT \n",
    "    ot.store_id,\n",
    "    ot.opening_times,\n",
    "    ARRAY_AGG(\n",
    "        ARRAY[\n",
    "            EXTRACT(epoch FROM ucl.start_time_utc)::text,\n",
    "            EXTRACT(epoch FROM ucl.end_time_utc)::text\n",
    "        ]\n",
    "    ) FILTER (WHERE ucl.start_time_utc <= '2018-03-13'::date AND ucl.end_time_utc >= '2018-03-12'::date) as closures_utc\n",
    "FROM opening_times ot\n",
    "LEFT JOIN unplanned_closure_log ucl ON ot.store_id = ucl.store_id\n",
    "GROUP BY ot.store_id, ot.opening_times\n",
    "ORDER BY ot.store_id;\n",
    "\"\"\")\n",
    "\n",
    "store_data = cursor.fetchall()\n",
    "\n",
    "## YOUR CODE HERE\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import pytz\n",
    "\n",
    "results = []\n",
    "\n",
    "for store_id, opening_times_json, closures_utc in store_data:\n",
    "    opening_data = json.loads(opening_times_json)\n",
    "    store_timezone = pytz.timezone(opening_data['timezone'])\n",
    "    \n",
    "    # 2018-03-12 was a Monday (day 1)\n",
    "    day_key = '1'  # Monday\n",
    "    \n",
    "    # Calculate total scheduled opening hours for the day\n",
    "    total_scheduled_hours = 0\n",
    "    if day_key in opening_data:\n",
    "        for period in opening_data[day_key]:\n",
    "            opening_time = period['opening']\n",
    "            closing_time = period['closing']\n",
    "            \n",
    "            # Handle 24-hour opening (00:00 to 00:00)\n",
    "            if opening_time == \"00:00\" and closing_time == \"00:00\":\n",
    "                total_scheduled_hours = 24\n",
    "            else:\n",
    "                # Parse times\n",
    "                open_hour, open_min = map(int, opening_time.split(':'))\n",
    "                close_hour, close_min = map(int, closing_time.split(':'))\n",
    "                \n",
    "                # Calculate hours\n",
    "                open_minutes = open_hour * 60 + open_min\n",
    "                close_minutes = close_hour * 60 + close_min\n",
    "                \n",
    "                # Handle overnight periods\n",
    "                if close_minutes <= open_minutes:\n",
    "                    close_minutes += 24 * 60\n",
    "                \n",
    "                period_hours = (close_minutes - open_minutes) / 60\n",
    "                total_scheduled_hours += period_hours\n",
    "    \n",
    "    # Calculate closure time in local timezone for 2018-03-12\n",
    "    closure_hours = 0\n",
    "    if closures_utc and closures_utc[0] is not None:\n",
    "        # Convert 2018-03-12 to UTC bounds for this timezone\n",
    "        local_start = store_timezone.localize(datetime(2018, 3, 12, 0, 0, 0))\n",
    "        local_end = store_timezone.localize(datetime(2018, 3, 12, 23, 59, 59))\n",
    "        utc_start = local_start.astimezone(timezone.utc)\n",
    "        utc_end = local_end.astimezone(timezone.utc)\n",
    "        \n",
    "        for closure in closures_utc:\n",
    "            if closure is not None:\n",
    "                closure_start_ts = float(closure[0])\n",
    "                closure_end_ts = float(closure[1])\n",
    "                \n",
    "                closure_start_utc = datetime.fromtimestamp(closure_start_ts, tz=timezone.utc)\n",
    "                closure_end_utc = datetime.fromtimestamp(closure_end_ts, tz=timezone.utc)\n",
    "                \n",
    "                # Find overlap with the local day\n",
    "                overlap_start = max(closure_start_utc, utc_start)\n",
    "                overlap_end = min(closure_end_utc, utc_end)\n",
    "                \n",
    "                if overlap_start < overlap_end:\n",
    "                    overlap_seconds = (overlap_end - overlap_start).total_seconds()\n",
    "                    closure_hours += overlap_seconds / 3600\n",
    "    \n",
    "    # Calculate proportion open\n",
    "    actual_open_hours = max(0, total_scheduled_hours - closure_hours)\n",
    "    proportion_open = actual_open_hours / 24.0 if total_scheduled_hours > 0 else 0\n",
    "    \n",
    "    results.append((store_id, proportion_open))\n",
    "\n",
    "# Print results\n",
    "for store_id, proportion in results:\n",
    "    print(f\"{store_id}, {proportion:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5a. City working days bit flags\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "Cities may also have working days configured defining days of the week in which they are open.\n",
    "\n",
    "In this case you will need to handle this data, stored as a bit flag (an integer whose binary representation specifies on which days of the week the city is open).\n",
    "\n",
    "We would like to know which cities are open on both Wednesdays and Thursdays.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "In the table *city_work_days* you will find the days of the week which the cities are opened for, stored as a bit flag (i.e. an integer between 0 and 127 inclusive in this case).\n",
    "\n",
    "The days of the week are ordered from 1 to 7 from Monday to Sunday.\n",
    "\n",
    "In binary, these correspond to the least to most significant bits (i.e. Monday is represented by the least significant bit, and Sunday by the most significant bit).\n",
    "\n",
    "I.e. a city only open on Mondays would have a value 1. A city only open on Mondays and Tuesdays would have a value of 3. A city open only on Sundays would have a value of 64.\n",
    "\n",
    "Which cities are open on both Wednesdays and Thursdays?\n",
    "\n",
    "Give the answer as a list of city codes in ascending order, i.e.:\n",
    "\n",
    "```\n",
    "[\"BCN\", \"MAD\"]\n",
    "```\n",
    "\n",
    "Try to do this in SQL only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BUE', 'CAI', 'MAD']\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Find cities open on both Wednesdays (bit 3, value 4) and Thursdays (bit 4, value 8)\n",
    "-- Days: Monday=1, Tuesday=2, Wednesday=4, Thursday=8, Friday=16, Saturday=32, Sunday=64\n",
    "-- Need cities where (work_days & 4) > 0 AND (work_days & 8) > 0\n",
    "\n",
    "SELECT city_code\n",
    "FROM city_work_days\n",
    "WHERE (work_days & 4) > 0  -- Wednesday bit set\n",
    "  AND (work_days & 8) > 0  -- Thursday bit set\n",
    "ORDER BY city_code;\n",
    "\"\"\")\n",
    "\n",
    "result = cursor.fetchall()\n",
    "cities = [row[0] for row in result]\n",
    "print(cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5b. City working days bit flags\n",
    "\n",
    "**Justification:**\n",
    "\n",
    "We might also want to look at the relationships between cities with this data.\n",
    "\n",
    "We would like to know on which days of the week Madrid (MAD), Barcelona (BCN) and Cairo (CAI) are all open.\n",
    "\n",
    "**Details:**\n",
    "\n",
    "On which days of the week are MAD, BCN and CAI all open?\n",
    "\n",
    "Give the answer as a list of day names in ascending order, i.e.: \n",
    "```\n",
    "[\"Tuesday\", \"Friday\"]\n",
    "```\n",
    "\n",
    "Try to do this in SQL only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monday', 'Tuesday', 'Thursday', 'Sunday']\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"\"\"\n",
    "-- YOUR QUERY HERE\n",
    "-- Find days when MAD, BCN, and CAI are all open\n",
    "-- Need to find common bits across all three cities\n",
    "-- Days: Monday=1, Tuesday=2, Wednesday=4, Thursday=8, Friday=16, Saturday=32, Sunday=64\n",
    "\n",
    "WITH city_bits AS (\n",
    "    SELECT \n",
    "        work_days,\n",
    "        city_code\n",
    "    FROM city_work_days \n",
    "    WHERE city_code IN ('MAD', 'BCN', 'CAI')\n",
    "),\n",
    "common_days AS (\n",
    "    -- Find bitwise AND of all three cities\n",
    "    SELECT \n",
    "        (SELECT work_days FROM city_bits WHERE city_code = 'MAD') &\n",
    "        (SELECT work_days FROM city_bits WHERE city_code = 'BCN') &\n",
    "        (SELECT work_days FROM city_bits WHERE city_code = 'CAI') as common_bits\n",
    "),\n",
    "day_names AS (\n",
    "    SELECT 1 as bit_value, 'Monday' as day_name\n",
    "    UNION ALL SELECT 2, 'Tuesday'\n",
    "    UNION ALL SELECT 4, 'Wednesday' \n",
    "    UNION ALL SELECT 8, 'Thursday'\n",
    "    UNION ALL SELECT 16, 'Friday'\n",
    "    UNION ALL SELECT 32, 'Saturday'\n",
    "    UNION ALL SELECT 64, 'Sunday'\n",
    ")\n",
    "SELECT day_name\n",
    "FROM day_names, common_days\n",
    "WHERE (common_bits & bit_value) > 0\n",
    "ORDER BY bit_value;\n",
    "\"\"\")\n",
    "\n",
    "result = cursor.fetchall()\n",
    "days = [row[0] for row in result]\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic\n",
    "\n",
    "These questions are designed to test your general analytic and problem-solving skills.\n",
    "\n",
    "\n",
    "### Q1. Courier arrivals\n",
    "\n",
    "Courier A arrives between 1pm and 3pm with uniform probability, Courier B arrives between 2pm and 4pm with uniform probability.\n",
    "\n",
    "What is the probability that courier A arrives before courier B?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated probability that courier A arrives before courier B: 0.875391\n",
      "Analytical probability: 0.875000\n",
      "Final answer: 0.875391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(123)\n",
    "trials = 1e6\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# Courier A arrives between 1pm and 3pm (uniform distribution)\n",
    "# Courier B arrives between 2pm and 4pm (uniform distribution)\n",
    "# Find probability that A arrives before B\n",
    "\n",
    "# Let's use a coordinate system where 1pm = 0, so:\n",
    "# A arrives between 0 and 2 hours\n",
    "# B arrives between 1 and 3 hours\n",
    "\n",
    "courier_a_arrivals = np.random.uniform(0, 2, int(trials))  # 0 to 2 hours after 1pm\n",
    "courier_b_arrivals = np.random.uniform(1, 3, int(trials))  # 1 to 3 hours after 1pm\n",
    "\n",
    "# Count cases where A arrives before B\n",
    "a_before_b = np.sum(courier_a_arrivals < courier_b_arrivals)\n",
    "\n",
    "probability = a_before_b / trials\n",
    "print(f\"Simulated probability that courier A arrives before courier B: {probability:.6f}\")\n",
    "\n",
    "# Let's also calculate this analytically\n",
    "# The sample space is [0,2] × [1,3]\n",
    "# We want P(A < B) where A ~ U(0,2) and B ~ U(1,3)\n",
    "# This is the area where a < b divided by total area (2 × 2 = 4)\n",
    "\n",
    "# The region where A < B is bounded by:\n",
    "# 0 ≤ a ≤ 2, 1 ≤ b ≤ 3, a < b\n",
    "# We need to integrate over this region\n",
    "\n",
    "# Case 1: 1 ≤ b ≤ 2, then 0 ≤ a < b\n",
    "# Case 2: 2 < b ≤ 3, then 0 ≤ a < 2\n",
    "\n",
    "# Area = ∫[1,2] b db + ∫[2,3] 2 db\n",
    "# = [b²/2] from 1 to 2 + [2b] from 2 to 3\n",
    "# = (4/2 - 1/2) + (6 - 4) = 1.5 + 2 = 3.5\n",
    "\n",
    "analytical_prob = 3.5 / 4.0\n",
    "print(f\"Analytical probability: {analytical_prob:.6f}\")\n",
    "\n",
    "# Final answer\n",
    "print(f\"Final answer: {probability:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Two-headed coin in a bag\n",
    "\n",
    "You have a bag of 1000 coins, in which one coin is two-headed. \n",
    "\n",
    "You take out one coin from the bag and flip it N times - obtaining heads every time.\n",
    "\n",
    "Calculate the probability that you have taken the two-headed coin, for each $N$ in $0<=N<=20$ (i.e. at each flip what is the probability that you are holding the two-headed coin). \n",
    "\n",
    "Note that $N=0$ corresponds to no observations, i.e. your prior belief.\n",
    "\n",
    "Give the probabilities to 3 decimal places.\n",
    "\n",
    "Your output should be of the form: N, probability\n",
    "\n",
    "For each N between 0 and 20 inclusive as described above (cumulative flips), where probability is a numeric value between 0 and 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 0.001\n",
      "1, 0.002\n",
      "2, 0.004\n",
      "3, 0.008\n",
      "4, 0.016\n",
      "5, 0.031\n",
      "6, 0.060\n",
      "7, 0.114\n",
      "8, 0.204\n",
      "9, 0.339\n",
      "10, 0.506\n",
      "11, 0.672\n",
      "12, 0.804\n",
      "13, 0.891\n",
      "14, 0.943\n",
      "15, 0.970\n",
      "16, 0.985\n",
      "17, 0.992\n",
      "18, 0.996\n",
      "19, 0.998\n",
      "20, 0.999\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "# Bayesian inference problem\n",
    "# Prior: P(two-headed coin) = 1/1000, P(normal coin) = 999/1000\n",
    "# Likelihood: P(heads | two-headed) = 1, P(heads | normal) = 0.5\n",
    "# We observe N consecutive heads\n",
    "\n",
    "# Using Bayes' theorem: P(two-headed | N heads) = P(N heads | two-headed) * P(two-headed) / P(N heads)\n",
    "\n",
    "results = []\n",
    "\n",
    "for N in range(21):  # N from 0 to 20\n",
    "    # Prior probabilities\n",
    "    p_two_headed = 1/1000\n",
    "    p_normal = 999/1000\n",
    "    \n",
    "    # Likelihood of observing N consecutive heads\n",
    "    p_n_heads_given_two_headed = 1.0  # Always heads with two-headed coin\n",
    "    p_n_heads_given_normal = (0.5) ** N  # (1/2)^N for normal coin\n",
    "    \n",
    "    # Total probability of observing N heads\n",
    "    p_n_heads = (p_n_heads_given_two_headed * p_two_headed + \n",
    "                 p_n_heads_given_normal * p_normal)\n",
    "    \n",
    "    # Posterior probability using Bayes' theorem\n",
    "    p_two_headed_given_n_heads = (p_n_heads_given_two_headed * p_two_headed) / p_n_heads\n",
    "    \n",
    "    results.append((N, round(p_two_headed_given_n_heads, 3)))\n",
    "\n",
    "# Print results\n",
    "for N, prob in results:\n",
    "    print(f\"{N}, {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Total number of digits written for ID numbers\n",
    "\n",
    "A series of sequential ID numbers (1,2,3..) writes 145579 digits when printed - how many individual ID numbers were printed?\n",
    "\n",
    "i.e. if  2 IDs had been printed, 2 digits would have been printed in total (1, 2).\n",
    "\n",
    "If 12 IDs had been printed, 15 digits would have been printed in total.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total digits written: 145579\n",
      "Number of ID numbers printed: 31337\n",
      "Verification - digits for 31337 numbers: 145579\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# Sequential ID numbers 1,2,3,... write 145579 digits total\n",
    "# Need to find how many ID numbers were printed\n",
    "\n",
    "# Count digits by ranges:\n",
    "# 1-digit numbers: 1-9 (9 numbers, 9 digits total)\n",
    "# 2-digit numbers: 10-99 (90 numbers, 180 digits total)  \n",
    "# 3-digit numbers: 100-999 (900 numbers, 2700 digits total)\n",
    "# 4-digit numbers: 1000-9999 (9000 numbers, 36000 digits total)\n",
    "# etc.\n",
    "\n",
    "target_digits = 145579\n",
    "total_digits = 0\n",
    "total_numbers = 0\n",
    "\n",
    "# Count by digit length\n",
    "digit_length = 1\n",
    "while total_digits < target_digits:\n",
    "    if digit_length == 1:\n",
    "        # 1-digit numbers: 1-9\n",
    "        numbers_in_range = 9\n",
    "    else:\n",
    "        # n-digit numbers: 10^(n-1) to 10^n - 1\n",
    "        numbers_in_range = 9 * (10 ** (digit_length - 1))\n",
    "    \n",
    "    digits_in_range = numbers_in_range * digit_length\n",
    "    \n",
    "    if total_digits + digits_in_range <= target_digits:\n",
    "        # We can include all numbers of this digit length\n",
    "        total_digits += digits_in_range\n",
    "        total_numbers += numbers_in_range\n",
    "        digit_length += 1\n",
    "    else:\n",
    "        # We need only part of this range\n",
    "        remaining_digits = target_digits - total_digits\n",
    "        remaining_numbers = remaining_digits // digit_length\n",
    "        total_numbers += remaining_numbers\n",
    "        break\n",
    "\n",
    "print(f\"Total digits written: {target_digits}\")\n",
    "print(f\"Number of ID numbers printed: {total_numbers}\")\n",
    "\n",
    "# Verification: let's check our answer\n",
    "verification_digits = 0\n",
    "for i in range(1, total_numbers + 1):\n",
    "    verification_digits += len(str(i))\n",
    "\n",
    "print(f\"Verification - digits for {total_numbers} numbers: {verification_digits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Unique number of toys in each box\n",
    "\n",
    "A child has M boxes and N toys. What is the minimum number of toys that the child must have, in order to fill each box with a different number of toys (including 0 toys) for a given number of boxes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxes: 1, Minimum toys: 0\n",
      "Boxes: 2, Minimum toys: 1\n",
      "Boxes: 3, Minimum toys: 3\n",
      "Boxes: 4, Minimum toys: 6\n",
      "Boxes: 5, Minimum toys: 10\n",
      "Boxes: 10, Minimum toys: 45\n"
     ]
    }
   ],
   "source": [
    "def minimum_toys(num_boxes: int) -> int:\n",
    "    ### YOUR CODE HERE\n",
    "    # Need to fill each box with a different number of toys (including 0)\n",
    "    # To minimize total toys, use consecutive integers starting from 0\n",
    "    # For M boxes, use: 0, 1, 2, 3, ..., M-1 toys\n",
    "    # Total toys = 0 + 1 + 2 + ... + (M-1) = M*(M-1)/2\n",
    "    \n",
    "    min_toys = num_boxes * (num_boxes - 1) // 2\n",
    "    return min_toys\n",
    "\n",
    "# Test the function\n",
    "test_cases = [1, 2, 3, 4, 5, 10]\n",
    "for boxes in test_cases:\n",
    "    toys = minimum_toys(boxes)\n",
    "    print(f\"Boxes: {boxes}, Minimum toys: {toys}\")\n",
    "\n",
    "# Explanation:\n",
    "# 1 box: [0] -> 0 toys\n",
    "# 2 boxes: [0, 1] -> 1 toy  \n",
    "# 3 boxes: [0, 1, 2] -> 3 toys\n",
    "# 4 boxes: [0, 1, 2, 3] -> 6 toys\n",
    "# This follows the formula n*(n-1)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
