<!DOCTYPE html>
<html lang="en">
    <head>
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta http-equiv="content-type" content="text/html; charset=utf-8">

      <!-- Enable responsiveness on mobile devices-->
      <!-- viewport-fit=cover is to support iPhone X rounded corners and notch in landscape-->
      <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1, viewport-fit=cover">

      <title>An introduction to Data Oriented Design with Rust</title>
      <meta name="author" content="James McMurray">
      <meta name="description" content="A technical blog about Rust, Linux and other topics.">
      <!-- CSS -->
      <link rel="stylesheet" href="https://jamesmcm.github.io/octozola.css">
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
      <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
      <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

      <!-- TODO: Move to config -->
      <link href="/favicon.png" rel="icon">
      
      
        <link rel="alternate" type="application/atom+xml" title="RSS" href="https://jamesmcm.github.io/atom.xml">
      
      

      
      
    </head>

    <body>
      
        <header role="banner">
          <hgroup>
		  <h1><a href="/">James McMurray&#x27;s Blog</a></h1>
		  <h2>Rust, Linux and other curiosities</h2>
          </hgroup>
        </header>
      

<nav role="navigation">

<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
	  <input type="hidden" name="q" value="site:jamesmcm.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search" data-_extension-text-contrast="">
  </fieldset>
</form>
  
<!-- TODO: Generate from links -->
<fieldset class="mobile-nav">
	<select onChange="window.location.href=this.value">
		<option value="">Navigate…</option>
		<option value="/">» Home</option>
		<option value="/blog">» Blog</option>
		<option disabled>---</option>
		<option value="/atom.xml">» RSS Feed</option>
		<option value="https://www.linkedin.com/in/james-mcmurray/">» LinkedIn</option>
		<option value="https://github.com/jamesmcm">» Github</option>
	</select>
</fieldset>
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/blog">Blog</a></li>
</ul>
<ul class="side-links">
  <li><a href="/atom.xml" rel="subscribe-rss" title="Subscribe via RSS">RSS</a></li>
  <li><a href="https://www.linkedin.com/in/james-mcmurray/">LinkedIn</a></li>
  <li><a href="https://github.com/jamesmcm">Github</a></li>
</ul>
</nav>

<div class="content">

<div class="blog-content-page">
<article>
  <h1 class="post-title">An introduction to Data Oriented Design with Rust</h1>
  <span class="post-date">2020-07-25</span>
  <hr class="within-post">
  <p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented Design</a> using Rust.</p>
<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>
<span id="continue-reading"></span><h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>
<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton's <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">"Data-Oriented Design and C++"</a> talk
if you haven't seen it already.</p>
<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>
<ul>
<li>Struct of arrays vs. array of structs</li>
<li>The cost of branching inside a hot loop</li>
<li>Linked List vs. Vector iteration</li>
<li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>
<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>
<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a>
refers to two contrasting ways of organising entity data to be operated
over.</p>
<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub struct </span><span>Player {
</span><span>    </span><span style="color:#bf616a;">name</span><span>: String,
</span><span>    </span><span style="color:#bf616a;">health</span><span>: </span><span style="color:#b48ead;">f64</span><span>,
</span><span>    </span><span style="color:#bf616a;">location</span><span>: (</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>),
</span><span>    </span><span style="color:#bf616a;">velocity</span><span>: (</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>),
</span><span>    </span><span style="color:#bf616a;">acceleration</span><span>: (</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>),
</span><span>}
</span></code></pre>
<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_oop</span><span>(</span><span style="color:#bf616a;">players</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Vec&lt;Player&gt;) {
</span><span>    </span><span style="color:#b48ead;">for</span><span> player in players.</span><span style="color:#96b5b4;">iter_mut</span><span>() {
</span><span>        player.location = (
</span><span>            player.location.</span><span style="color:#d08770;">0 </span><span>+ player.velocity.</span><span style="color:#d08770;">0</span><span>,
</span><span>            player.location.</span><span style="color:#d08770;">1 </span><span>+ player.velocity.</span><span style="color:#d08770;">1</span><span>,
</span><span>        );
</span><span>        player.velocity = (
</span><span>            player.velocity.</span><span style="color:#d08770;">0 </span><span>+ player.acceleration.</span><span style="color:#d08770;">0</span><span>,
</span><span>            player.velocity.</span><span style="color:#d08770;">1 </span><span>+ player.acceleration.</span><span style="color:#d08770;">1</span><span>,
</span><span>        );
</span><span>    }
</span><span>}
</span></code></pre>
<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>-- Vec&lt;Player&gt;
</span><span>name  (pointer to heap)  -- Player 1
</span><span>health    
</span><span>location0  (tuple split for clarity) 
</span><span>location1
</span><span>velocity0
</span><span>velocity1
</span><span>acceleration0
</span><span>acceleration1
</span><span>name  (pointer to heap)  -- Player 2
</span><span>location0    
</span><span>location1
</span><span>velocity0
</span><span>velocity1
</span><span>acceleration0
</span><span>acceleration1
</span><span>...
</span></code></pre>
<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>
<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub struct </span><span>DOPlayers {
</span><span>    </span><span style="color:#bf616a;">names</span><span>: Vec&lt;String&gt;,
</span><span>    </span><span style="color:#bf616a;">health</span><span>: Vec&lt;</span><span style="color:#b48ead;">f64</span><span>&gt;,
</span><span>    </span><span style="color:#bf616a;">locations</span><span>: Vec&lt;(</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>)&gt;,
</span><span>    </span><span style="color:#bf616a;">velocities</span><span>: Vec&lt;(</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>)&gt;,
</span><span>    </span><span style="color:#bf616a;">acceleration</span><span>: Vec&lt;(</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>)&gt;,
</span><span>}
</span></code></pre>
<p>Now we can do the same calculation as in the OOP case as follows:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_dop</span><span>(</span><span style="color:#bf616a;">world</span><span>: &amp;</span><span style="color:#b48ead;">mut</span><span> DOPlayers) {
</span><span>    </span><span style="color:#b48ead;">for </span><span>(pos, (vel, acc)) in world
</span><span>        .locations
</span><span>        .</span><span style="color:#96b5b4;">iter_mut</span><span>()
</span><span>        .</span><span style="color:#96b5b4;">zip</span><span>(world.velocities.</span><span style="color:#96b5b4;">iter_mut</span><span>().</span><span style="color:#96b5b4;">zip</span><span>(world.acceleration.</span><span style="color:#96b5b4;">iter</span><span>()))
</span><span>    {
</span><span>        *pos = (pos.</span><span style="color:#d08770;">0 </span><span>+ vel.</span><span style="color:#d08770;">0</span><span>, pos.</span><span style="color:#d08770;">1 </span><span>+ vel.</span><span style="color:#d08770;">1</span><span>);
</span><span>        *vel = (vel.</span><span style="color:#d08770;">0 </span><span>+ acc.</span><span style="color:#d08770;">0</span><span>, vel.</span><span style="color:#d08770;">1 </span><span>+ acc.</span><span style="color:#d08770;">1</span><span>);
</span><span>    }
</span><span>}
</span></code></pre>
<p>In this case the memory layout is as follows:</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>-- DOPlayers
</span><span>name1    -- names
</span><span>name2
</span><span>...
</span><span>health1    -- health
</span><span>health2
</span><span>...
</span><span>location1    -- locations
</span><span>location2
</span><span>...
</span></code></pre>
<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>
<h3 id="benchmark">Benchmark</h3>
<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>
<p><img src="https://jamesmcm.github.io/blog/intro-dod/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark" /></p>
<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>
<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>
<pre data-lang="asm" style="background-color:#2b303b;color:#c0c5ce;" class="language-asm "><code class="language-asm" data-lang="asm"><span style="color:#8fa1b3;">// Relevant OOP </span><span style="color:#b48ead;">loop
</span><span style="color:#8fa1b3;">.LBB0_2:
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">32</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">48</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm2</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">64</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">32</span><span>], </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm2</span><span>, </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">48</span><span>], </span><span style="color:#bf616a;">xmm2
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdx</span><span>, </span><span style="color:#d08770;">80
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rcx</span><span>, </span><span style="color:#bf616a;">rdx
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">.LBB0_2
</span><span>
</span><span style="color:#8fa1b3;">// ...
</span><span style="color:#8fa1b3;">// Relevant DOP </span><span style="color:#b48ead;">loop
</span><span style="color:#8fa1b3;">.LBB1_7:
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">r9 </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>- </span><span style="color:#d08770;">16</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdi</span><span>, </span><span style="color:#d08770;">2
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm0</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">r9 </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">addpd   </span><span style="color:#bf616a;">xmm1</span><span>, </span><span style="color:#bf616a;">xmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">movupd  </span><span style="color:#8fa1b3;">xmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx</span><span>], </span><span style="color:#bf616a;">xmm1
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdx</span><span>, </span><span style="color:#d08770;">32
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rsi</span><span>, </span><span style="color:#bf616a;">rdi
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">.LBB1_7
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">test    </span><span style="color:#bf616a;">r8</span><span>, </span><span style="color:#bf616a;">r8
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">je      </span><span style="color:#8fa1b3;">.LBB1_5
</span></code></pre>
<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>
<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>
<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>
<pre data-lang="asm" style="background-color:#2b303b;color:#c0c5ce;" class="language-asm "><code class="language-asm" data-lang="asm"><span style="color:#8fa1b3;">// OOP </span><span style="color:#b48ead;">loop
</span><span style="color:#8fa1b3;">.LBB0_2:
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#bf616a;">ymm0</span><span>, </span><span style="color:#8fa1b3;">ymmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">32</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vaddpd  </span><span style="color:#bf616a;">ymm0</span><span>, </span><span style="color:#bf616a;">ymm0</span><span>, </span><span style="color:#8fa1b3;">ymmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">48</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">ymmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rax </span><span>+ </span><span style="color:#bf616a;">rdx </span><span>+ </span><span style="color:#d08770;">32</span><span>], </span><span style="color:#bf616a;">ymm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdx</span><span>, </span><span style="color:#d08770;">80
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">cmp     </span><span style="color:#bf616a;">rcx</span><span>, </span><span style="color:#bf616a;">rdx
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">.LBB0_2
</span><span>
</span><span style="color:#8fa1b3;">...
</span><span style="color:#8fa1b3;">// DOP </span><span style="color:#b48ead;">loop
</span><span style="color:#8fa1b3;">.LBB1_19:
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rsi </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vaddpd  </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rsi </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>], </span><span style="color:#8fa1b3;">zmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vaddpd  </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">r10 </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax </span><span>- </span><span style="color:#d08770;">64</span><span>], </span><span style="color:#8fa1b3;">zmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rsi </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vaddpd  </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rsi </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>], </span><span style="color:#8fa1b3;">zmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vaddpd  </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmm0</span><span>, </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">r10 </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>]
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">vmovupd </span><span style="color:#8fa1b3;">zmmword </span><span style="color:#96b5b4;">ptr </span><span>[</span><span style="color:#bf616a;">rcx </span><span>+ </span><span style="color:#d08770;">4</span><span>*</span><span style="color:#bf616a;">rax</span><span>], </span><span style="color:#8fa1b3;">zmm0
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">r11</span><span>, </span><span style="color:#d08770;">8
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rax</span><span>, </span><span style="color:#d08770;">32
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">add     </span><span style="color:#bf616a;">rdi</span><span>, </span><span style="color:#d08770;">2
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">jne     </span><span style="color:#8fa1b3;">.LBB1_19
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">test    </span><span style="color:#bf616a;">r9</span><span>, </span><span style="color:#bf616a;">r9
</span><span style="color:#8fa1b3;">        </span><span style="color:#b48ead;">je      </span><span style="color:#8fa1b3;">.LBB1_22
</span></code></pre>
<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>
<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>
<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>
<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>
<h3 id="summary">Summary</h3>
<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>
<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>
<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>
<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>
<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>
<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>
<p>Another optimisation tactic is to avoid branching in any "hot" parts of
the code (i.e. any part that will be executed many, many times).</p>
<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type as follows:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">enum </span><span>NodeType {
</span><span>  Player,
</span><span>  PhysicsObject,
</span><span>  Script,
</span><span>}
</span><span>
</span><span style="color:#b48ead;">struct </span><span>Node {
</span><span style="color:#bf616a;">node_type</span><span>: NodeType,
</span><span style="color:#bf616a;">position</span><span>: (</span><span style="color:#b48ead;">f64</span><span>, </span><span style="color:#b48ead;">f64</span><span>),
</span><span style="color:#65737e;">// ...
</span><span>}
</span></code></pre>
<p>And then pattern match on <code>node_type</code> when we need to operate on a Node.
The problem comes when we have a <code>Vec&lt;Node&gt;</code> with tens of thousands of
elements, which we might need to operate on every frame. By using
<code>node.node_type</code> to decide the logic to use, we need to check
that for every element (since the order of the <code>node_type</code>'s within the
<code>Vec&lt;Node&gt;</code> is unknown).</p>
<p>Not only does this comparison mean we must do an extra operation for
every element, but it also impedes auto-vectorisation, since our
relevant nodes (of the same <code>node_type</code>) may not be stored contiguously.</p>
<p>The data-oriented approach is to split these nodes up by <code>node_type</code>.
Ideally creating a separate struct per node type, or at least
separating them in separate Vectors before the hot loop. This means we
don't need to check the <code>node_type</code> inside the hot loop, and we can take
advantage of the fact that the nodes we do operate on will be stored in
contiguous memory.</p>
<h3 id="benchmark-1">Benchmark</h3>
<p>In this benchmark we use the following code:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span>#[</span><span style="color:#bf616a;">derive</span><span>(Copy, Clone)]
</span><span style="color:#b48ead;">pub struct </span><span>Foo {
</span><span>    </span><span style="color:#bf616a;">x</span><span>: </span><span style="color:#b48ead;">i32</span><span>,
</span><span>    </span><span style="color:#bf616a;">calc_type</span><span>: CalcType,
</span><span>}
</span><span>
</span><span>#[</span><span style="color:#bf616a;">derive</span><span>(Copy, Clone)]
</span><span style="color:#b48ead;">pub enum </span><span>CalcType {
</span><span>    Identity,
</span><span>    Square,
</span><span>    Cube,
</span><span>}
</span><span>
</span><span style="color:#65737e;">// ...
</span><span>
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_mixed</span><span>(</span><span style="color:#bf616a;">x</span><span>: &amp;[Foo]) -&gt; Vec&lt;</span><span style="color:#b48ead;">i32</span><span>&gt; {
</span><span>    x.</span><span style="color:#96b5b4;">into_iter</span><span>()
</span><span>        .</span><span style="color:#96b5b4;">map</span><span>(|</span><span style="color:#bf616a;">x</span><span>| </span><span style="color:#b48ead;">match</span><span> x.calc_type {
</span><span>            CalcType::Identity =&gt; x.x,
</span><span>            CalcType::Square =&gt; x.x * x.x,
</span><span>            CalcType::Cube =&gt; x.x * x.x * x.x,
</span><span>        })
</span><span>        .</span><span style="color:#96b5b4;">collect</span><span>()
</span><span>}
</span><span>
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_separate</span><span>(</span><span style="color:#bf616a;">x</span><span>: &amp;[Foo], </span><span style="color:#bf616a;">y</span><span>: &amp;[Foo], </span><span style="color:#bf616a;">z</span><span>: &amp;[Foo]) -&gt; (Vec&lt;</span><span style="color:#b48ead;">i32</span><span>&gt;, Vec&lt;</span><span style="color:#b48ead;">i32</span><span>&gt;, Vec&lt;</span><span style="color:#b48ead;">i32</span><span>&gt;) {
</span><span>    </span><span style="color:#b48ead;">let</span><span> x = x.</span><span style="color:#96b5b4;">into_iter</span><span>().</span><span style="color:#96b5b4;">map</span><span>(|</span><span style="color:#bf616a;">x</span><span>| x.x).</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>    </span><span style="color:#b48ead;">let</span><span> y = y.</span><span style="color:#96b5b4;">into_iter</span><span>().</span><span style="color:#96b5b4;">map</span><span>(|</span><span style="color:#bf616a;">x</span><span>| x.x * x.x).</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>    </span><span style="color:#b48ead;">let</span><span> z = z.</span><span style="color:#96b5b4;">into_iter</span><span>().</span><span style="color:#96b5b4;">map</span><span>(|</span><span style="color:#bf616a;">x</span><span>| x.x * x.x * x.x).</span><span style="color:#96b5b4;">collect</span><span>();
</span><span>    (x, y, z)
</span><span>}
</span></code></pre>
<p>Comparing the case of a mixed vector of Foos, and separate vector of
Foos split by <code>calc_type</code>.</p>
<p>The results of the benchmark are as follows:</p>
<p><img src="https://jamesmcm.github.io/blog/intro-dod/innercheck.svg" alt="Loop branch benchmark" title="Loop branch benchmark" /></p>
<p>Overall, we see that the data-oriented approach finishes in about a
quarter of the time.</p>
<p>The <a href="https://godbolt.org/z/6ocTx8">output on Godbolt</a> is less clear this
time, but we can see that there seems to be some unrolling in the
separate case that isn't possible in the mixed case due to the need to
check the <code>calc_type</code> in that case.</p>
<h3 id="summary-1">Summary</h3>
<p>The concept of moving any instructions you can outside of hot loops
should be familiar, but this example also demonstrates how it can impact
vectorisation.</p>
<h2 id="indirection-iteration-in-a-linked-list">Indirection: Iteration in a Linked List</h2>
<p>In this example we will compare iterating through a (doubly) linked list
vs. a vector. This case is well-known and mentioned in <a href="https://doc.rust-lang.org/beta/std/collections/struct.LinkedList.html">Rust's
LinkedList docs</a>,
in <a href="https://doc.rust-lang.org/beta/std/collections/index.html#use-a-linkedlist-when">Rust's std::collections docs</a>
and in <a href="https://rust-unofficial.github.io/too-many-lists/#an-obligatory-public-service-announcement">Learn Rust With Entirely Too Many Linked Lists' Public Service Announcement</a>.
The latter Public Service Announcement covers a lot of cases where
Linked Lists are commonly used, so I recommend reading that if you
haven't already. Nevertheless, the proof is in the pudding, so I think
it's useful to see a benchmark directly.</p>
<p>A Linked List stores elements <em>indirectly</em>, that is, it stores an
element and a pointer to the next element. This means that consecutive
elements in the linked list are <em>not</em> stored in consecutive memory
locations.</p>
<p>This leads to two issues that impede vectorisation:</p>
<ul>
<li>The elements of the linked list may be stored arbitrarily far apart, so
we cannot just load a block of memory to the CPU cache to operate on
them simultaneously.</li>
<li>We have to dereference a pointer to get the next element in the list.</li>
</ul>
<p>For example, we might store a vector of i32s on the heap as follows
(holding a pointer to the start of the vector, the vector capacity and
the vector length, on the stack):</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>0x00 1
</span><span>0x01 2
</span><span>0x02 3
</span><span>...
</span></code></pre>
<p>The values are stored contiguously, whereas for a (singly) linked list, we could
have the following case.</p>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>0x00 1
</span><span>0x01 0x14
</span><span>0x0C 3
</span><span>0x0D 0
</span><span>...
</span><span>0x14 2
</span><span>0x15 0x0C
</span></code></pre>
<p>Here the values are not stored in contiguous memory (or even necessarily
in the same order as their pointers maintain in the list).</p>
<h3 id="benchmark-2">Benchmark</h3>
<p>In this case the benchmark is very simple, simply squaring all of the
elements of a linked list and a vector:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_list</span><span>(</span><span style="color:#bf616a;">list</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>LinkedList&lt;</span><span style="color:#b48ead;">i32</span><span>&gt;) {
</span><span>    list.</span><span style="color:#96b5b4;">iter_mut</span><span>().</span><span style="color:#96b5b4;">for_each</span><span>(|</span><span style="color:#bf616a;">x</span><span>| {
</span><span>        *x = *x * *x;
</span><span>    });
</span><span>}
</span><span>
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_vec</span><span>(</span><span style="color:#bf616a;">list</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Vec&lt;</span><span style="color:#b48ead;">i32</span><span>&gt;) {
</span><span>    list.</span><span style="color:#96b5b4;">iter_mut</span><span>().</span><span style="color:#96b5b4;">for_each</span><span>(|</span><span style="color:#bf616a;">x</span><span>| {
</span><span>        *x = *x * *x;
</span><span>    });
</span><span>}
</span></code></pre>
<p>The results are as follows:</p>
<p><img src="https://jamesmcm.github.io/blog/intro-dod/linkedlist.svg" alt="LinkedList benchmark" title="LinkedList benchmark" /></p>
<p>Overall, we see that the data-oriented approach finishes in about a
tenth of the time.</p>
<p>The <a href="https://godbolt.org/z/EzznM1">output on Godbolt</a> shows the
unrolling in the Vec case that isn't possible in the LinkedList case.</p>
<h2 id="summary-2">Summary</h2>
<p>This case is well-known and demonstrates the biggest difference of all
of the benchmarks. Note that here we look only at iteration, and not at
other operations which could be considered to somewhat favour Linked
Lists such as insertion, where it avoids the (amortised) cost of vector
resizing, however as argued in <a href="https://rust-unofficial.github.io/too-many-lists/#i-cant-afford-amortization">Learn Rust With Entirely Too Many Linked
Lists</a>
this can be avoided in Vectors too.</p>
<p>Hopefully this will become common knowledge and we'll see fewer
interview questions and practice problems based around linked lists and
indirection, considering only Big O complexity and not real world
performance.</p>
<h2 id="indirection-dynamic-dispatch-vs-monomorphisation">Indirection: Dynamic Dispatch vs. Monomorphisation</h2>
<p>When writing generic functions (i.e. for any types implementing certain
Traits), we have the choice between <a href="https://doc.rust-lang.org/book/ch17-02-trait-objects.html">dynamic dispatch</a>
and monomorphisation.</p>
<p>Dynamic dispatch allows us to work with a mixed
collection of trait objects, i.e. we can have a <code>Vec&lt;Box&lt;dyn MyTrait&gt;&gt;</code>
which can contain references to different types which all implement
MyTrait. The trait object contains a pointer to the instance of the
struct itself (implementing MyTrait) and a pointer to the struct's virtual method table
(or vtable, a lookup table pointing to the implementation of each method
of MyTrait). Then when we call a method on one of these trait objects, at
runtime we work out which implementation of the method to use by
consulting the vtable.</p>
<p>Note that this implies indirection. Our vector has to be of pointers to
the struct instances themselves (since the different structs implementing
MyTrait can differ in size and fields), and we must also
dereference the pointer in the vtable to find out
which implementation to call.</p>
<p>Monomorphisation, on the other hand, creates a separate implementation
of the generic function for each possible type. For example, the
following code would actually create two separate functions for
<code>run_vecs_square()</code> for the <code>Foo</code> and <code>Bar</code> types respectively:</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub struct </span><span>Foo {
</span><span>    </span><span style="color:#bf616a;">id</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>}
</span><span>
</span><span style="color:#b48ead;">pub struct </span><span>Bar {
</span><span>    </span><span style="color:#bf616a;">id</span><span>: </span><span style="color:#b48ead;">usize</span><span>,
</span><span>}
</span><span>
</span><span style="color:#b48ead;">pub trait </span><span>MyTrait {
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">square_id</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl </span><span>MyTrait </span><span style="color:#b48ead;">for </span><span>Foo {
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">square_id</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.id = </span><span style="color:#bf616a;">self</span><span>.id * </span><span style="color:#bf616a;">self</span><span>.id;
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">impl </span><span>MyTrait </span><span style="color:#b48ead;">for </span><span>Bar {
</span><span>    </span><span style="color:#b48ead;">fn </span><span style="color:#8fa1b3;">square_id</span><span>(&amp;</span><span style="color:#b48ead;">mut </span><span style="color:#bf616a;">self</span><span>) {
</span><span>        </span><span style="color:#bf616a;">self</span><span>.id = </span><span style="color:#bf616a;">self</span><span>.id * </span><span style="color:#bf616a;">self</span><span>.id * </span><span style="color:#bf616a;">self</span><span>.id;
</span><span>    }
</span><span>}
</span><span>
</span><span>
</span><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_vecs_square</span><span>&lt;T: MyTrait&gt;(</span><span style="color:#bf616a;">x</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Vec&lt;T&gt;) {
</span><span>    x.</span><span style="color:#96b5b4;">iter_mut</span><span>().</span><span style="color:#96b5b4;">for_each</span><span>(|</span><span style="color:#bf616a;">x</span><span>| x.</span><span style="color:#96b5b4;">square_id</span><span>())
</span><span>}
</span></code></pre>
<p>This increases the binary size, but gives us an easy way of generating
multiple implementations of a function for different types and allows us
to avoid indirection (i.e. note we can use <code>Vec&lt;T&gt;</code> and don't need to
use <code>Vec&lt;Box&lt;T&gt;&gt;</code>).</p>
<p>Whereas in the following code, we use dynamic dispatch. There is only
one implementation of <code>run_dyn_square</code> but exactly which implementation
of <code>square_id()</code> it should call is determined at runtime by consulting
the trait object's vtable.</p>
<pre data-lang="rust" style="background-color:#2b303b;color:#c0c5ce;" class="language-rust "><code class="language-rust" data-lang="rust"><span style="color:#b48ead;">pub fn </span><span style="color:#8fa1b3;">run_dyn_square</span><span>(</span><span style="color:#bf616a;">x</span><span>: &amp;</span><span style="color:#b48ead;">mut </span><span>Vec&lt;Box&lt;dyn MyTrait&gt;&gt;) {
</span><span>    x.</span><span style="color:#96b5b4;">iter_mut</span><span>().</span><span style="color:#96b5b4;">for_each</span><span>(|</span><span style="color:#bf616a;">x</span><span>| x.</span><span style="color:#96b5b4;">square_id</span><span>())
</span><span>}
</span></code></pre>
<p>This can be more convenient, as we can create the vector containing
references to different types with no worry about what the actual types
are (only that they implement MyTrait), and we don't inflate the binary
size. However, we are forced to use indirection, since the underlying
types could have different sizes, and as we saw with the LinkedList
example this can have significant implications for auto-vectorisation.</p>
<h3 id="benchmark-3">Benchmark</h3>
<p>Using the example above, the benchmark results are as follows:</p>
<p><img src="https://jamesmcm.github.io/blog/intro-dod/dyntrait.svg" alt="Dynamic Dispatch benchmark" title="Dynamic Dispatch benchmark" /></p>
<p>Overall, we see that the monomorphised example finishes in about a
quarter of the time of the dynamic dispatch one. The monomorphised case
with indirection (<code>Vec&lt;Box&lt;T&gt;&gt;</code>) is only slightly faster than the
dynamic dispatch case which implies that most of the performance gap is
due to the added indirection impeding vectorisation, whereas the vtable lookup
itself only adds a small constant overhead.</p>
<p>Unfortunately, in this case <a href="https://godbolt.org/z/46WYaP">Godbolt</a>
doesn't include the target functions in the generated output.</p>
<h3 id="summary-3">Summary</h3>
<p>This benchmark showed that the main cost of dynamic dispatch is in
impeding vectorisation due to the necessary introduction of indirection,
and that the cost of the lookup in the vtable itself was relatively
small.</p>
<p>This means that you should definitely consider designing for
monomorphisation if your methods are doing operations that would greatly
benefit from vectorisation (such as the mathematical operations above).
On the other hand, if they are carrying out operations that are not
vectorised (for example, constructing Strings) then dynamic dispatch may
have a negligible cost overall.</p>
<p>As always, benchmark your specific use cases and access patterns when
comparing different possible implementations.</p>
<h2 id="conclusion">Conclusion</h2>
<p>In this article we have seen four cases where considering data layout in
memory, and the realities and limitations of the CPU cache has lead to
significant performance improvements.</p>
<p>This only scratches the surface of data-oriented design and optimisation. For example,
<a href="http://www.catb.org/esr/structure-packing/">structure packing</a>, padding
and alignment was not covered. The <a href="https://www.dataorienteddesign.com/dodbook/">data-oriented design book</a> by
Richard Fabian also covers some additional topics.</p>
<p>It is important to note that in all of our examples, we did not modify
the algorithms we used. All implementations for each case have the same
Big O complexity, and yet in practice the performance can vary greatly,
with speedups from 2x-10x available just by optimising for
vectorisation and other features of modern CPUs.</p>
<p>In summary:</p>
<ul>
<li>Favour data structures with less/no indirection and contiguous memory
(you'll also have an easier time with the borrow checker!).</li>
<li>Avoid branching inside loops.</li>
<li>Benchmark your use cases and access patterns.</li>
<li>If deploying performance sensitive code, consider targeting the CPU
features of your destination machine (i.e. <a href="https://rust-lang.github.io/packed_simd/perf-guide/target-feature/rustflags.html">use RUSTFLAGS</a>).</li>
<li><a href="https://github.com/bheisler/criterion.rs">Criterion</a> is a great benchmarking tool.</li>
<li><a href="https://github.com/gnzlbg/cargo-asm">cargo-asm</a> and <a href="https://godbolt.org/">Godbolt</a> can be used to inspect the generated assembly (and
LLVM intermediate representation).</li>
<li><a href="https://rust-lang.github.io/packed_simd/perf-guide/prof/linux.html">perf</a> and <a href="https://github.com/flamegraph-rs/flamegraph">flamegraph</a> can be used for performance profiling.</li>
</ul>

</article>
<hr class="end-post">
<nav class="pagination">
    
        <a class="previous" href="https://jamesmcm.github.io/blog/rust-ses/">‹ Newer Post</a>
    
    <a class="top" href="#top">Back to top</a>
    
    <a class="next" href="https://jamesmcm.github.io/blog/a-practical-introduction-to-async-programming-in-rust/">Older Post ›</a>
    
</nav>
</div>

</div>


<footer role="contentinfo">

<p>
Copyright © 2025 - James McMurray -
  <span class="credit">Powered by <a href="https://www.getzola.org/">Zola</a></span>
</p>

</footer>
</body>

</html>
